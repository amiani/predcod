{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of zero-divergence Inference Learning in a Predictive Coding Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Coding Network\n",
    "\n",
    "A predictive coding network is a probabilistic model that calculates.\n",
    "\n",
    "Variables on adjacent levels are assumed to be related by\n",
    "\n",
    "$$ P(x_i^l | \\bar x^{l+1}) = \\mathcal{N}( x_i^l; \\mu_i^l, \\Sigma_i^l) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mu_i^l = {\\theta_i^l}^T f(\\bar x^{l+1}) $$\n",
    "\n",
    "with the objective being to maximize\n",
    "\n",
    "$$ F = \\ln P(\\bar x^1,...,\\bar x^{L-1} | \\bar x^L) $$\n",
    "\n",
    "due to the assumed relationship between adjacent layers this simplifies to\n",
    "\n",
    "$$ \\begin{align*}\n",
    "    F &= \\sum_{l=0}^{L-1} \\ln P(\\bar x^l | \\bar x^{l+1})    \\\\\n",
    "    &= \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\ln \\mathcal{N}( x_i^l; \\mu_i^l, \\Sigma_i^l)    \\\\\n",
    "    &= \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\ln \\frac{1}{\\sqrt{2\\pi\\Sigma_i^l}} - \\frac{1}{2}\\frac{(x_i^l - \\mu_i^l)^2}{\\Sigma_i^l}\n",
    "\\end{align*} $$\n",
    "\n",
    "ignoring the constant term (since we are going to use the derivative with respect to $x_i^l$)\n",
    "\n",
    "$$ F = -\\frac{1}{2} \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\frac{(x_i^l - \\mu_i^l)^2}{\\Sigma_i^l} $$\n",
    "\n",
    "In this model we will assume the variances to be 1, and letting $\\epsilon_i^l = x_i^l - \\mu_i^l$\n",
    "\n",
    "$$ F = -\\frac{1}{2} \\sum_{l=0}^{L-1} \\sum_{i=1}^n (\\epsilon_i^l)^2 $$\n",
    "\n",
    "to update each $x_i$ we will use the partial derivative of $F$ with respect to $x_i$\n",
    "\n",
    "$$ \\frac{\\partial F}{x_i^l} = -\\epsilon_i^l + f'(x_i^l) \\sum_{k=1}^n \\theta_{i,k}^l \\epsilon_k^{l-1}$$\n",
    "\n",
    "updating the weights\n",
    "$$ \\frac{\\partial F}{\\theta_{i,j}^l} = \\epsilon_i^l f(x_j^{l-1}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_image import *\n",
    "\n",
    "train_images = read_mnist_images('data/train-images-idx3-ubyte.gz')\n",
    "train_labels = read_mnist_labels('data/train-images-idx3-ubyte.gz')\n",
    "test_images = read_mnist_images('data/t10k-images-idx3-ubyte.gz')\n",
    "test_labels = read_mnist_labels('data/t10k-images-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "\n",
    "y = np.array([[0],\n",
    "            [1],\n",
    "            [1],\n",
    "            [0]])\n",
    "\n",
    "w1 = 2*np.random.random((4,3)) - 1\n",
    "w2 = 2*np.random.random((1,4)) - 1\n",
    "\n",
    "h = np.zeros((4,1))\n",
    "\n",
    "# prediction\n",
    "# 1. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "02555e9c35705c811b2eb2b2f878ae2f6197d21dc22eadcc1ae8478b206bf640"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('comp361': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}