{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of zero-divergence Inference Learning in a Predictive Coding Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Coding Network\n",
    "\n",
    "A predictive coding network is a probabilistic model that calculates.\n",
    "\n",
    "Variables on adjacent levels are assumed to be related by\n",
    "\n",
    "$$ P(x_i^l | \\bar x^{l+1}) = \\mathcal{N}( x_i^l; \\mu_i^l, \\Sigma_i^l) $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\mu_i^l = {\\theta_i^l}^T f(\\bar x^{l+1}) $$\n",
    "\n",
    "with the objective being to maximize\n",
    "\n",
    "$$ F = \\ln P(\\bar x^1,...,\\bar x^{L-1} | \\bar x^L) $$\n",
    "\n",
    "due to the assumed relationship between adjacent layers this simplifies to\n",
    "\n",
    "$$ \\begin{align*}\n",
    "    F &= \\sum_{l=0}^{L-1} \\ln P(\\bar x^l | \\bar x^{l+1})    \\\\\n",
    "    &= \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\ln \\mathcal{N}( x_i^l; \\mu_i^l, \\Sigma_i^l)    \\\\\n",
    "    &= \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\ln \\frac{1}{\\sqrt{2\\pi\\Sigma_i^l}} - \\frac{1}{2}\\frac{(x_i^l - \\mu_i^l)^2}{\\Sigma_i^l}\n",
    "\\end{align*} $$\n",
    "\n",
    "ignoring the constant term (since we are going to use the derivative with respect to $x_i^l$)\n",
    "\n",
    "$$ F = -\\frac{1}{2} \\sum_{l=0}^{L-1} \\sum_{i=1}^n \\frac{(x_i^l - \\mu_i^l)^2}{\\Sigma_i^l} $$\n",
    "\n",
    "In this model we will assume the variances to be 1, and letting $\\epsilon_i^l = x_i^l - \\mu_i^l$\n",
    "\n",
    "$$ F = -\\frac{1}{2} \\sum_{l=0}^{L-1} \\sum_{i=1}^n (\\epsilon_i^l)^2 $$\n",
    "\n",
    "to update each $x_i$ we will use the partial derivative of $F$ with respect to $x_i$\n",
    "\n",
    "$$ \\frac{\\partial F}{x_i^l} = -\\epsilon_i^l + f'(x_i^l) \\sum_{k=1}^n \\theta_{i,k}^l \\epsilon_k^{l-1}$$\n",
    "\n",
    "updating the weights\n",
    "$$ \\frac{\\partial F}{\\theta_{i,j}^l} = \\epsilon_i^{l-1} f(x_j^l) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from read_image import *\n",
    "\n",
    "train_images = read_mnist_images('data/train-images-idx3-ubyte.gz')\n",
    "train_labels = read_mnist_labels('data/train-images-idx3-ubyte.gz')\n",
    "test_images = read_mnist_images('data/t10k-images-idx3-ubyte.gz')\n",
    "test_labels = read_mnist_labels('data/t10k-images-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.]]\n",
      "[[1.00005653]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "input = np.array([[0,0,1],\n",
    "            [0,1,1],\n",
    "            [1,0,1],\n",
    "            [1,1,1]])\n",
    "\n",
    "output = np.array([[0],\n",
    "            [1],\n",
    "            [1],\n",
    "            [0]])\n",
    "\n",
    "#w1 = 2*np.random.random((4,1)) - 1\n",
    "#w2 = 2*np.random.random((3,4)) - 1\n",
    "w1 = np.array([ [1.],    \n",
    "                [2]])\n",
    "w2 = np.array([ [1.,2],\n",
    "                [3,4],\n",
    "                [5,6]])\n",
    "params = [w2, w1]\n",
    "\n",
    "layers = [np.zeros((3,1)), np.zeros((2,1)), np.zeros((1,1))]\n",
    "\n",
    "# prediction\n",
    "gamma = 1\n",
    "def predict(input: np.ndarray) -> np.ndarray:\n",
    "    layers = [np.zeros((3,1)), np.zeros((2,1)), np.zeros((1,1))]\n",
    "    curr_mu = params[0].T.dot(input)\n",
    "    curr_err = layers[1] - curr_mu\n",
    "    for i in range(1, len(layers)-1):\n",
    "        activated = np.maximum(0, layers[i])\n",
    "        next_mu = params[i].T.dot(activated)\n",
    "        next_err = layers[i+1] - next_mu\n",
    "        relu_mask = layers[i] > 0\n",
    "        layers[i] += gamma * (-curr_err + relu_mask * params[i].dot(next_err))\n",
    "        #during prediction can just do a normal forward pass through network\n",
    "        curr_mu = params[i].T.dot(np.maximum(0, layers[i]))\n",
    "        curr_err = layers[i+1] - curr_mu\n",
    "    layers[-1] += gamma * -curr_err\n",
    "    return layers[-1]\n",
    "\n",
    "def learn(input: np.ndarray, out: np.ndarray, lr=0.01):\n",
    "    layers[2] = out\n",
    "    for t in range(0, len(layers)):\n",
    "        curr_mu = params[0].T.dot(input)\n",
    "        curr_err = layers[1] - curr_mu\n",
    "        if t == len(layers) - 1:\n",
    "            params[0] += lr * input.dot(curr_err.T)\n",
    "        for i in range(1, len(layers)-1):\n",
    "            activated = np.maximum(0, layers[i])\n",
    "            next_mu = params[i].T.dot(activated)\n",
    "            next_err = layers[i+1] - next_mu\n",
    "            relu_mask = layers[i] > 0\n",
    "            layers[i] += gamma * (-curr_err + relu_mask * params[i].dot(next_err))\n",
    "            if len(layers) - 1 - i == t:\n",
    "                activated = np.maximum(0, layers[i])\n",
    "                next_mu = params[i].T.dot(activated)\n",
    "                next_err = layers[i+1] - next_mu\n",
    "                #print(params[i])\n",
    "                params[i] += lr * activated.dot(next_err.T)\n",
    "                #print(params[i])\n",
    "            #can we avoid recalculating curr_mu during learning?\n",
    "            #during prediction can just do a normal forward pass through network\n",
    "            curr_mu = params[i].T.dot(np.maximum(0, layers[i]))\n",
    "            curr_err = layers[i+1] - curr_mu\n",
    "    \n",
    "print(predict(input[1].reshape((3,1))))\n",
    "learn(input[1].reshape((3,1)), output[1], 0.1)\n",
    "#print(layers)\n",
    "print(predict(input[1].reshape((3,1))))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2b47fb9f8a43b2379e79497425d2a2e979e2426e74b41ed9428e9101717abc52"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('predcod': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}